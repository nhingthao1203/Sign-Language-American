{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98296fc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:42.990430Z",
     "iopub.status.busy": "2025-04-24T06:53:42.990170Z",
     "iopub.status.idle": "2025-04-24T06:53:55.066672Z",
     "shell.execute_reply": "2025-04-24T06:53:55.066080Z"
    },
    "papermill": {
     "duration": 12.081367,
     "end_time": "2025-04-24T06:53:55.067994",
     "exception": false,
     "start_time": "2025-04-24T06:53:42.986627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593a6b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.073112Z",
     "iopub.status.busy": "2025-04-24T06:53:55.072776Z",
     "iopub.status.idle": "2025-04-24T06:53:55.128451Z",
     "shell.execute_reply": "2025-04-24T06:53:55.127839Z"
    },
    "papermill": {
     "duration": 0.059589,
     "end_time": "2025-04-24T06:53:55.129931",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.070342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e44791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.135848Z",
     "iopub.status.busy": "2025-04-24T06:53:55.135530Z",
     "iopub.status.idle": "2025-04-24T06:53:55.150787Z",
     "shell.execute_reply": "2025-04-24T06:53:55.149829Z"
    },
    "papermill": {
     "duration": 0.020116,
     "end_time": "2025-04-24T06:53:55.152539",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.132423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset  # Import Dataset\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, num_frames=16):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.classes = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        \n",
    "        # Lấy video và nhãn từ thư mục\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_path, class_name)\n",
    "            for video_folder in os.listdir(class_dir):\n",
    "                video_path = os.path.join(class_dir, video_folder)\n",
    "                if os.path.isdir(video_path):\n",
    "                    self.samples.append((video_path, self.class_to_idx[class_name]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.samples[idx]\n",
    "        frame_files = sorted([f for f in os.listdir(video_path) if f.endswith('.jpg')])\n",
    "        frames = []\n",
    "        \n",
    "        # Chọn num_frames frame, hoặc tất cả frame nếu ít hơn\n",
    "        actual_num_frames = min(self.num_frames, len(frame_files))\n",
    "        selected_indices = np.linspace(0, len(frame_files) - 1, num=actual_num_frames, dtype=int)\n",
    "        \n",
    "        for i in selected_indices:\n",
    "            if i < len(frame_files):\n",
    "                frame_path = os.path.join(video_path, frame_files[i])\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is None:\n",
    "                    frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                frames.append(frame)\n",
    "        \n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "        \n",
    "        frames = torch.stack(frames)\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7156e77b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.159676Z",
     "iopub.status.busy": "2025-04-24T06:53:55.159414Z",
     "iopub.status.idle": "2025-04-24T06:53:55.165424Z",
     "shell.execute_reply": "2025-04-24T06:53:55.164959Z"
    },
    "papermill": {
     "duration": 0.010913,
     "end_time": "2025-04-24T06:53:55.166854",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.155941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SingleFrameCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5):\n",
    "        super(SingleFrameCNN, self).__init__()\n",
    "        \n",
    "        # Sử dụng ResNet18 đã được pre-trained\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # Bỏ fully connected layer cuối\n",
    "        \n",
    "        # MLP để phân loại\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)  # 512 là kích thước đầu ra của ResNet\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, c, h, w = x.shape\n",
    "        # Reshape để xử lý từng frame một\n",
    "        x = x.view(batch_size * num_frames, c, h, w)\n",
    "        # Trích xuất đặc trưng từ ResNet\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        # Reshape lại để MLP xử lý\n",
    "        x = x.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Đưa qua MLP để phân loại (làm việc với các đặc trưng đã trích xuất)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Tính trung bình các logits (sau khi qua MLP)\n",
    "        x = x.mean(dim=1)  # Trung bình trên các frame\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7e625e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.172199Z",
     "iopub.status.busy": "2025-04-24T06:53:55.171965Z",
     "iopub.status.idle": "2025-04-24T06:53:55.181131Z",
     "shell.execute_reply": "2025-04-24T06:53:55.180294Z"
    },
    "papermill": {
     "duration": 0.013477,
     "end_time": "2025-04-24T06:53:55.182602",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.169125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, classes):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(min(20, len(classes)), min(18, len(classes))))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "    # F1 Score and Recall\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    return test_loss, test_acc, f1, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30320c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.190079Z",
     "iopub.status.busy": "2025-04-24T06:53:55.189658Z",
     "iopub.status.idle": "2025-04-24T06:53:55.193272Z",
     "shell.execute_reply": "2025-04-24T06:53:55.192720Z"
    },
    "papermill": {
     "duration": 0.008184,
     "end_time": "2025-04-24T06:53:55.194305",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.186121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74e5d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.199093Z",
     "iopub.status.busy": "2025-04-24T06:53:55.198884Z",
     "iopub.status.idle": "2025-04-24T06:53:55.209881Z",
     "shell.execute_reply": "2025-04-24T06:53:55.209205Z"
    },
    "papermill": {
     "duration": 0.014667,
     "end_time": "2025-04-24T06:53:55.210932",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.196265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25, scheduler=None, early_stopping_patience=7):\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Lists to store training history\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Track the actual number of epochs completed due to early stopping\n",
    "    actual_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {epoch_train_acc:.2f}%\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * correct / total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Step the scheduler if applicable\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_single_frame_cnn_model.pth')\n",
    "            print(f\"  Saved best model with val accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  Early stopping patience: {patience_counter}/{early_stopping_patience}\")\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Count the actual number of epochs run\n",
    "        actual_epochs = epoch + 1\n",
    "\n",
    "    # Plot training and validation loss/accuracy with dynamic epoch count\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_losses[:actual_epochs], label='Train Loss')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_losses[:actual_epochs], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_accuracies[:actual_epochs], label='Train Accuracy')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_accuracies[:actual_epochs], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c0e7c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.215817Z",
     "iopub.status.busy": "2025-04-24T06:53:55.215571Z",
     "iopub.status.idle": "2025-04-24T06:53:55.223816Z",
     "shell.execute_reply": "2025-04-24T06:53:55.223296Z"
    },
    "papermill": {
     "duration": 0.011826,
     "end_time": "2025-04-24T06:53:55.224733",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.212907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Cấu hình dữ liệu\n",
    "    data_root = '/kaggle/input/msasl-process/processdata'\n",
    "    train_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Train')\n",
    "    val_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Val')\n",
    "    test_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Test')\n",
    "    \n",
    "    # Các tham số huấn luyện\n",
    "    batch_size = 32\n",
    "    num_frames = 16\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Định nghĩa các phép biến đổi \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomCrop(224, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Tạo datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset = VideoFrameDataset(train_data_path, transform=transform, num_frames=num_frames)\n",
    "    val_dataset = VideoFrameDataset(val_data_path, transform=transform, num_frames=num_frames)\n",
    "    test_dataset = VideoFrameDataset(test_data_path, transform=transform, num_frames=num_frames)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Tạo dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Lấy danh sách các lớp\n",
    "    classes = train_dataset.classes\n",
    "    num_classes = len(classes)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    print(\"Initializing Single-Frame CNN model...\")\n",
    "    model = SingleFrameCNN(num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Định nghĩa loss function và optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=num_epochs, scheduler=scheduler, early_stopping_patience=10\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    test_loss, test_acc, f1, recall = evaluate_model(model, test_loader, criterion, classes)\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'classes': classes,\n",
    "        'test_acc': test_acc,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "    }, 'single_frame_cnn_final_model.pth')\n",
    "    \n",
    "    print(f\"Final model saved with test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8a2001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:53:55.230582Z",
     "iopub.status.busy": "2025-04-24T06:53:55.230375Z",
     "iopub.status.idle": "2025-04-24T09:32:37.734028Z",
     "shell.execute_reply": "2025-04-24T09:32:37.733033Z"
    },
    "papermill": {
     "duration": 9522.507353,
     "end_time": "2025-04-24T09:32:37.735252",
     "exception": false,
     "start_time": "2025-04-24T06:53:55.227899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train samples: 3495\n",
      "Val samples: 850\n",
      "Test samples: 1335\n",
      "Number of classes: 154\n",
      "Initializing Single-Frame CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 211MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 4.9376, Train Accuracy: 3.26%\n",
      "Epoch 1/50, Validation Loss: 4.7768, Validation Accuracy: 5.53%\n",
      "  Saved best model with val accuracy: 5.53%\n",
      "Epoch 2/50, Train Loss: 4.2071, Train Accuracy: 15.25%\n",
      "Epoch 2/50, Validation Loss: 4.3929, Validation Accuracy: 9.29%\n",
      "  Saved best model with val accuracy: 9.29%\n",
      "Epoch 3/50, Train Loss: 3.6309, Train Accuracy: 26.98%\n",
      "Epoch 3/50, Validation Loss: 4.1405, Validation Accuracy: 13.53%\n",
      "  Saved best model with val accuracy: 13.53%\n",
      "Epoch 4/50, Train Loss: 3.1227, Train Accuracy: 39.74%\n",
      "Epoch 4/50, Validation Loss: 3.9739, Validation Accuracy: 17.29%\n",
      "  Saved best model with val accuracy: 17.29%\n",
      "Epoch 5/50, Train Loss: 2.6733, Train Accuracy: 51.30%\n",
      "Epoch 5/50, Validation Loss: 3.7807, Validation Accuracy: 21.53%\n",
      "  Saved best model with val accuracy: 21.53%\n",
      "Epoch 6/50, Train Loss: 2.2754, Train Accuracy: 60.17%\n",
      "Epoch 6/50, Validation Loss: 3.6052, Validation Accuracy: 22.71%\n",
      "  Saved best model with val accuracy: 22.71%\n",
      "Epoch 7/50, Train Loss: 1.9371, Train Accuracy: 67.15%\n",
      "Epoch 7/50, Validation Loss: 3.4605, Validation Accuracy: 26.82%\n",
      "  Saved best model with val accuracy: 26.82%\n",
      "Epoch 8/50, Train Loss: 1.6328, Train Accuracy: 74.22%\n",
      "Epoch 8/50, Validation Loss: 3.3549, Validation Accuracy: 27.88%\n",
      "  Saved best model with val accuracy: 27.88%\n",
      "Epoch 9/50, Train Loss: 1.3679, Train Accuracy: 79.89%\n",
      "Epoch 9/50, Validation Loss: 3.2451, Validation Accuracy: 31.18%\n",
      "  Saved best model with val accuracy: 31.18%\n",
      "Epoch 10/50, Train Loss: 1.1467, Train Accuracy: 83.81%\n",
      "Epoch 10/50, Validation Loss: 3.1183, Validation Accuracy: 35.18%\n",
      "  Saved best model with val accuracy: 35.18%\n",
      "Epoch 11/50, Train Loss: 0.9823, Train Accuracy: 85.87%\n",
      "Epoch 11/50, Validation Loss: 3.1188, Validation Accuracy: 30.47%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 12/50, Train Loss: 0.7972, Train Accuracy: 90.33%\n",
      "Epoch 12/50, Validation Loss: 3.0221, Validation Accuracy: 34.82%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 13/50, Train Loss: 0.6842, Train Accuracy: 92.42%\n",
      "Epoch 13/50, Validation Loss: 2.9754, Validation Accuracy: 35.88%\n",
      "  Saved best model with val accuracy: 35.88%\n",
      "Epoch 14/50, Train Loss: 0.5640, Train Accuracy: 94.16%\n",
      "Epoch 14/50, Validation Loss: 2.9629, Validation Accuracy: 35.88%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 15/50, Train Loss: 0.4728, Train Accuracy: 95.22%\n",
      "Epoch 15/50, Validation Loss: 2.9309, Validation Accuracy: 35.53%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 16/50, Train Loss: 0.3885, Train Accuracy: 96.31%\n",
      "Epoch 16/50, Validation Loss: 2.9331, Validation Accuracy: 37.06%\n",
      "  Saved best model with val accuracy: 37.06%\n",
      "Epoch 17/50, Train Loss: 0.3239, Train Accuracy: 97.45%\n",
      "Epoch 17/50, Validation Loss: 2.8408, Validation Accuracy: 37.65%\n",
      "  Saved best model with val accuracy: 37.65%\n",
      "Epoch 18/50, Train Loss: 0.2747, Train Accuracy: 97.88%\n",
      "Epoch 18/50, Validation Loss: 2.7361, Validation Accuracy: 38.12%\n",
      "  Saved best model with val accuracy: 38.12%\n",
      "Epoch 19/50, Train Loss: 0.2273, Train Accuracy: 98.28%\n",
      "Epoch 19/50, Validation Loss: 2.8265, Validation Accuracy: 37.65%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 20/50, Train Loss: 0.1921, Train Accuracy: 98.66%\n",
      "Epoch 20/50, Validation Loss: 2.9947, Validation Accuracy: 35.29%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 21/50, Train Loss: 0.1770, Train Accuracy: 98.60%\n",
      "Epoch 21/50, Validation Loss: 2.7596, Validation Accuracy: 39.41%\n",
      "  Saved best model with val accuracy: 39.41%\n",
      "Epoch 22/50, Train Loss: 0.1359, Train Accuracy: 99.11%\n",
      "Epoch 22/50, Validation Loss: 2.7136, Validation Accuracy: 41.76%\n",
      "  Saved best model with val accuracy: 41.76%\n",
      "Epoch 23/50, Train Loss: 0.1216, Train Accuracy: 99.31%\n",
      "Epoch 23/50, Validation Loss: 2.7862, Validation Accuracy: 38.59%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 24/50, Train Loss: 0.1041, Train Accuracy: 99.57%\n",
      "Epoch 24/50, Validation Loss: 2.7026, Validation Accuracy: 40.94%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 25/50, Train Loss: 0.1020, Train Accuracy: 99.31%\n",
      "Epoch 25/50, Validation Loss: 2.8053, Validation Accuracy: 38.94%\n",
      "  Early stopping patience: 3/10\n",
      "Epoch 26/50, Train Loss: 0.0906, Train Accuracy: 99.57%\n",
      "Epoch 26/50, Validation Loss: 2.9295, Validation Accuracy: 38.24%\n",
      "  Early stopping patience: 4/10\n",
      "Epoch 27/50, Train Loss: 0.0788, Train Accuracy: 99.46%\n",
      "Epoch 27/50, Validation Loss: 2.7806, Validation Accuracy: 38.24%\n",
      "  Early stopping patience: 5/10\n",
      "Epoch 28/50, Train Loss: 0.0902, Train Accuracy: 99.31%\n",
      "Epoch 28/50, Validation Loss: 2.8061, Validation Accuracy: 37.53%\n",
      "  Early stopping patience: 6/10\n",
      "Epoch 29/50, Train Loss: 0.0562, Train Accuracy: 99.63%\n",
      "Epoch 29/50, Validation Loss: 2.6987, Validation Accuracy: 41.65%\n",
      "  Early stopping patience: 7/10\n",
      "Epoch 30/50, Train Loss: 0.0432, Train Accuracy: 99.89%\n",
      "Epoch 30/50, Validation Loss: 2.6806, Validation Accuracy: 41.18%\n",
      "  Early stopping patience: 8/10\n",
      "Epoch 31/50, Train Loss: 0.0377, Train Accuracy: 99.91%\n",
      "Epoch 31/50, Validation Loss: 2.6886, Validation Accuracy: 39.88%\n",
      "  Early stopping patience: 9/10\n",
      "Epoch 32/50, Train Loss: 0.0361, Train Accuracy: 99.97%\n",
      "Epoch 32/50, Validation Loss: 2.6556, Validation Accuracy: 42.94%\n",
      "  Saved best model with val accuracy: 42.94%\n",
      "Epoch 33/50, Train Loss: 0.0328, Train Accuracy: 99.94%\n",
      "Epoch 33/50, Validation Loss: 2.6594, Validation Accuracy: 41.18%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 34/50, Train Loss: 0.0330, Train Accuracy: 99.94%\n",
      "Epoch 34/50, Validation Loss: 2.6650, Validation Accuracy: 41.41%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 35/50, Train Loss: 0.0301, Train Accuracy: 100.00%\n",
      "Epoch 35/50, Validation Loss: 2.6632, Validation Accuracy: 41.06%\n",
      "  Early stopping patience: 3/10\n",
      "Epoch 36/50, Train Loss: 0.0302, Train Accuracy: 99.97%\n",
      "Epoch 36/50, Validation Loss: 2.6594, Validation Accuracy: 40.59%\n",
      "  Early stopping patience: 4/10\n",
      "Epoch 37/50, Train Loss: 0.0276, Train Accuracy: 100.00%\n",
      "Epoch 37/50, Validation Loss: 2.6815, Validation Accuracy: 40.71%\n",
      "  Early stopping patience: 5/10\n",
      "Epoch 38/50, Train Loss: 0.0273, Train Accuracy: 99.97%\n",
      "Epoch 38/50, Validation Loss: 2.6865, Validation Accuracy: 41.18%\n",
      "  Early stopping patience: 6/10\n",
      "Epoch 39/50, Train Loss: 0.0272, Train Accuracy: 100.00%\n",
      "Epoch 39/50, Validation Loss: 2.6808, Validation Accuracy: 41.18%\n",
      "  Early stopping patience: 7/10\n",
      "Epoch 40/50, Train Loss: 0.0282, Train Accuracy: 100.00%\n",
      "Epoch 40/50, Validation Loss: 2.6833, Validation Accuracy: 40.59%\n",
      "  Early stopping patience: 8/10\n",
      "Epoch 41/50, Train Loss: 0.0266, Train Accuracy: 100.00%\n",
      "Epoch 41/50, Validation Loss: 2.6734, Validation Accuracy: 38.82%\n",
      "  Early stopping patience: 9/10\n",
      "Epoch 42/50, Train Loss: 0.0280, Train Accuracy: 100.00%\n",
      "Epoch 42/50, Validation Loss: 2.6696, Validation Accuracy: 42.00%\n",
      "  Early stopping patience: 10/10\n",
      "Early stopping triggered at epoch 42\n",
      "Evaluating model on test set...\n",
      "Test Loss: 1.4244, Test Accuracy: 68.09%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       0.50      1.00      0.67         2\n",
      "       again       0.17      0.40      0.24         5\n",
      "         all       0.00      0.00      0.00         4\n",
      "       apple       1.00      1.00      1.00         3\n",
      "        aunt       0.00      0.00      0.00         2\n",
      "         bad       0.00      0.00      0.00         2\n",
      "    bathroom       0.00      0.00      0.00         1\n",
      "   beautiful       0.00      0.00      0.00         6\n",
      "     bicycle       0.75      0.60      0.67         5\n",
      "       black       0.67      0.67      0.67         3\n",
      "        blue       0.25      0.50      0.33         2\n",
      "        book       0.67      0.25      0.36         8\n",
      "         boy       0.50      0.25      0.33         4\n",
      "   boyfriend       0.67      0.67      0.67         3\n",
      "     brother       0.11      0.20      0.14         5\n",
      "       brown       1.00      0.33      0.50         3\n",
      "         bus       0.00      0.00      0.00         2\n",
      "         bye       0.00      0.00      0.00         3\n",
      "       candy       0.40      1.00      0.57         2\n",
      "         cat       0.13      1.00      0.24         2\n",
      "      cheese       0.67      1.00      0.80         4\n",
      "       class       0.57      0.67      0.62         6\n",
      "      coffee       0.00      0.00      0.00         3\n",
      "     college       0.00      0.00      0.00         5\n",
      "       color       0.00      0.00      0.00         3\n",
      "    computer       0.00      0.00      0.00         2\n",
      "      cookie       0.00      0.00      0.00         2\n",
      "      cousin       0.25      0.67      0.36         3\n",
      "         cow       0.25      1.00      0.40         1\n",
      "       dance       0.57      0.80      0.67         5\n",
      "    daughter       0.20      0.33      0.25         3\n",
      "         day       0.00      0.00      0.00         4\n",
      "        deaf       0.67      0.29      0.40         7\n",
      "      doctor       0.27      0.60      0.37         5\n",
      "         dog       0.20      0.25      0.22         4\n",
      "        draw       0.00      0.00      0.00         3\n",
      "       drink       0.12      1.00      0.22         1\n",
      "       early       0.00      0.00      0.00         2\n",
      "         eat       0.50      0.50      0.50         4\n",
      "     english       0.60      0.75      0.67         4\n",
      "     excited       0.50      0.17      0.25         6\n",
      "      family       0.38      0.60      0.46         5\n",
      "      father       0.25      0.25      0.25         4\n",
      "        fine       0.00      0.00      0.00         5\n",
      "      finish       0.50      0.43      0.46         7\n",
      "        fish       0.09      0.33      0.14         3\n",
      "      forget       0.17      0.50      0.25         2\n",
      "      france       0.00      0.00      0.00         5\n",
      "      friend       0.33      0.67      0.44         3\n",
      "        girl       0.00      0.00      0.00         5\n",
      "        good       0.50      0.57      0.53         7\n",
      " grandfather       0.00      0.00      0.00         2\n",
      " grandmother       0.00      0.00      0.00         4\n",
      "       green       0.25      0.50      0.33         2\n",
      "       happy       0.46      0.67      0.55         9\n",
      "        have       1.00      0.33      0.50         6\n",
      "     hearing       0.50      0.50      0.50         2\n",
      "       hello       0.60      0.20      0.30        15\n",
      "        help       0.00      0.00      0.00         3\n",
      "        here       0.22      0.67      0.33         3\n",
      "        home       0.40      0.67      0.50         3\n",
      "       horse       0.50      0.33      0.40         3\n",
      "        hour       0.50      0.33      0.40         3\n",
      "         how       0.75      0.60      0.67         5\n",
      "    how_many       0.67      1.00      0.80         6\n",
      "      hungry       0.00      0.00      0.00         2\n",
      "        hurt       0.60      0.75      0.67         4\n",
      "     husband       0.00      0.00      0.00         1\n",
      "      jacket       0.00      0.00      0.00         2\n",
      "        know       0.60      0.75      0.67         4\n",
      "       learn       0.40      0.33      0.36         6\n",
      "       light       0.00      0.00      0.00         7\n",
      "        like       0.00      0.00      0.00         5\n",
      "        live       0.60      0.75      0.67         4\n",
      "        lost       0.00      0.00      0.00         7\n",
      "         man       0.00      0.00      0.00         3\n",
      "       marry       0.00      0.00      0.00         3\n",
      "          me       1.00      0.33      0.50         3\n",
      "        meet       0.33      0.50      0.40         2\n",
      "        milk       0.00      0.00      0.00         2\n",
      "      monday       0.00      0.00      0.00         1\n",
      "      mother       0.00      0.00      0.00         2\n",
      "          my       0.38      0.75      0.50         4\n",
      "        name       1.00      0.67      0.80         3\n",
      "        nice       0.00      0.00      0.00         4\n",
      "       night       0.00      0.00      0.00         3\n",
      "          no       0.56      0.62      0.59         8\n",
      "    not know       0.00      0.00      0.00         2\n",
      "     nothing       0.00      0.00      0.00         4\n",
      "       nurse       0.50      0.20      0.29         5\n",
      "         old       0.00      0.00      0.00         1\n",
      "      orange       0.20      0.20      0.20         5\n",
      "       paper       0.50      0.25      0.33         8\n",
      "      pencil       0.25      0.33      0.29         3\n",
      "        pink       0.00      0.00      0.00         2\n",
      "        play       0.60      0.75      0.67         4\n",
      "      please       0.20      0.20      0.20         5\n",
      "   principal       1.00      0.50      0.67         2\n",
      "      purple       0.17      0.50      0.25         2\n",
      "       quiet       1.00      0.17      0.29         6\n",
      "        read       0.80      0.67      0.73         6\n",
      "         red       0.00      0.00      0.00         3\n",
      "       right       0.50      0.14      0.22         7\n",
      "      russia       0.00      0.00      0.00         4\n",
      "         sad       0.40      0.80      0.53         5\n",
      "        same       0.17      0.50      0.25         2\n",
      "    sandwich       0.00      0.00      0.00         2\n",
      "    saturday       1.00      0.33      0.50         3\n",
      "      school       0.18      0.25      0.21         8\n",
      "       shirt       0.00      0.00      0.00         2\n",
      "       shoes       0.50      0.50      0.50         2\n",
      "        sick       0.60      1.00      0.75         3\n",
      "        sign       0.17      0.25      0.20         8\n",
      "      sister       0.20      0.40      0.27         5\n",
      "         sit       1.00      0.50      0.67         6\n",
      "        slow       0.50      0.33      0.40         6\n",
      "      soccer       0.00      0.00      0.00         3\n",
      "        soda       0.50      1.00      0.67         1\n",
      "       sorry       0.00      0.00      0.00         4\n",
      "      spring       0.17      0.43      0.24         7\n",
      "     student       0.18      0.50      0.27         4\n",
      "      sunday       0.00      0.00      0.00         3\n",
      "       table       0.95      1.00      0.97        19\n",
      "         tea       1.00      0.90      0.95        20\n",
      "     teacher       0.97      0.97      0.97        39\n",
      "    thursday       1.00      0.76      0.86        21\n",
      "        time       0.84      0.93      0.88        28\n",
      "       tired       0.94      0.86      0.90        36\n",
      "       today       0.94      0.89      0.91        18\n",
      "    tomorrow       0.82      0.92      0.87        25\n",
      "      turkey       1.00      0.85      0.92        27\n",
      "       uncle       0.96      0.96      0.96        26\n",
      "  understand       0.93      0.83      0.88        30\n",
      "        walk       0.92      0.73      0.81        30\n",
      "        want       0.88      0.92      0.90        39\n",
      "       water       0.96      0.90      0.93        30\n",
      "   wednesday       0.81      0.77      0.79        22\n",
      "        what       0.84      0.91      0.88        35\n",
      "        when       0.71      0.89      0.79        28\n",
      "       where       0.91      0.97      0.94        30\n",
      "       white       0.97      0.88      0.92        33\n",
      "         who       0.94      0.81      0.87        21\n",
      "         why       1.00      0.89      0.94        18\n",
      "        wife       0.95      0.95      0.95        21\n",
      "       woman       0.91      0.81      0.86        26\n",
      "        wood       0.88      0.82      0.85        17\n",
      "        work       1.00      0.71      0.83        17\n",
      "       write       0.92      0.74      0.82        31\n",
      "       wrong       1.00      0.87      0.93        23\n",
      "        year       0.88      0.85      0.86        26\n",
      "      yellow       0.96      0.81      0.88        32\n",
      "         yes       1.00      0.95      0.97        37\n",
      "         you       0.96      0.85      0.90        27\n",
      "        your       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.68      1335\n",
      "   macro avg       0.43      0.45      0.41      1335\n",
      "weighted avg       0.72      0.68      0.69      1335\n",
      "\n",
      "F1 Score: 0.6851\n",
      "Recall: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved with test accuracy: 68.09%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7073108,
     "sourceId": 11325443,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9542.412942,
   "end_time": "2025-04-24T09:32:41.184520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-24T06:53:38.771578",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
