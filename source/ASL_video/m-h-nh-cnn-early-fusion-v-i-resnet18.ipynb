{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef96d23",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:27.691048Z",
     "iopub.status.busy": "2025-04-25T18:23:27.690840Z",
     "iopub.status.idle": "2025-04-25T18:23:46.058798Z",
     "shell.execute_reply": "2025-04-25T18:23:46.058035Z"
    },
    "papermill": {
     "duration": 18.372797,
     "end_time": "2025-04-25T18:23:46.060255",
     "exception": false,
     "start_time": "2025-04-25T18:23:27.687458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87d95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.065551Z",
     "iopub.status.busy": "2025-04-25T18:23:46.064994Z",
     "iopub.status.idle": "2025-04-25T18:23:46.159074Z",
     "shell.execute_reply": "2025-04-25T18:23:46.158299Z"
    },
    "papermill": {
     "duration": 0.097668,
     "end_time": "2025-04-25T18:23:46.160286",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.062618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880f5f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.164966Z",
     "iopub.status.busy": "2025-04-25T18:23:46.164751Z",
     "iopub.status.idle": "2025-04-25T18:23:46.172922Z",
     "shell.execute_reply": "2025-04-25T18:23:46.172262Z"
    },
    "papermill": {
     "duration": 0.011665,
     "end_time": "2025-04-25T18:23:46.173984",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.162319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, num_frames=16):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.classes = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        # Collect video samples\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_path, class_name)\n",
    "            for video_folder in os.listdir(class_dir):\n",
    "                video_path = os.path.join(class_dir, video_folder)\n",
    "                if os.path.isdir(video_path):\n",
    "                    self.samples.append((video_path, self.class_to_idx[class_name]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.samples[idx]\n",
    "        frame_files = sorted([f for f in os.listdir(video_path) if f.endswith('.jpg')])\n",
    "        frames = []\n",
    "\n",
    "        # Select num_frames frames, or less if there are fewer frames\n",
    "        actual_num_frames = min(self.num_frames, len(frame_files))\n",
    "        selected_indices = np.linspace(0, len(frame_files) - 1, num=actual_num_frames, dtype=int)\n",
    "\n",
    "        for i in selected_indices:\n",
    "            if i < len(frame_files):\n",
    "                frame_path = os.path.join(video_path, frame_files[i])\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is None:\n",
    "                    frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                frames.append(frame)\n",
    "\n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "\n",
    "        frames = torch.stack(frames)\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858d82bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.178394Z",
     "iopub.status.busy": "2025-04-25T18:23:46.178195Z",
     "iopub.status.idle": "2025-04-25T18:23:46.183268Z",
     "shell.execute_reply": "2025-04-25T18:23:46.182618Z"
    },
    "papermill": {
     "duration": 0.008516,
     "end_time": "2025-04-25T18:23:46.184402",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.175886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyFusionCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5, num_frames=16):\n",
    "        super(EarlyFusionCNN, self).__init__()\n",
    "\n",
    "        # Pre-trained ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the fully connected layer\n",
    "\n",
    "        # Number of frames\n",
    "        self.num_frames = num_frames\n",
    "\n",
    "        # MLP for classification\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)  # 512 is the output size from ResNet\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, c, h, w = x.shape\n",
    "\n",
    "        # Flatten the frames into a 4D tensor\n",
    "        x = x.view(batch_size * num_frames, c, h, w)  # (batch_size * num_frames, c, h, w)\n",
    "        \n",
    "        # Extract features from ResNet\n",
    "        x = self.resnet(x)\n",
    "\n",
    "        # Reshape to (batch_size, num_frames, 512)\n",
    "        x = x.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Combine features from frames (average over frames)\n",
    "        x = x.mean(dim=1)  # Averaging over frames\n",
    "        \n",
    "        # Pass through MLP for classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbacc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.188671Z",
     "iopub.status.busy": "2025-04-25T18:23:46.188478Z",
     "iopub.status.idle": "2025-04-25T18:23:46.194685Z",
     "shell.execute_reply": "2025-04-25T18:23:46.194056Z"
    },
    "papermill": {
     "duration": 0.009348,
     "end_time": "2025-04-25T18:23:46.195641",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.186293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, classes):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(min(20, len(classes)), min(18, len(classes))))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d5bc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.199936Z",
     "iopub.status.busy": "2025-04-25T18:23:46.199742Z",
     "iopub.status.idle": "2025-04-25T18:23:46.210385Z",
     "shell.execute_reply": "2025-04-25T18:23:46.209721Z"
    },
    "papermill": {
     "duration": 0.013977,
     "end_time": "2025-04-25T18:23:46.211372",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.197395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25, scheduler=None, early_stopping_patience=7):\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Lists to store training history\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Track the actual number of epochs completed due to early stopping\n",
    "    actual_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {epoch_train_acc:.2f}%\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * correct / total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Step the scheduler if applicable\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_early_fusion_cnn_model.pth')\n",
    "            print(f\"  Saved best model with val accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  Early stopping patience: {patience_counter}/{early_stopping_patience}\")\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Count the actual number of epochs run\n",
    "        actual_epochs = epoch + 1\n",
    "\n",
    "    # Plot training and validation loss/accuracy with dynamic epoch count\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_losses[:actual_epochs], label='Train Loss')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_losses[:actual_epochs], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_accuracies[:actual_epochs], label='Train Accuracy')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_accuracies[:actual_epochs], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ffc614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.215655Z",
     "iopub.status.busy": "2025-04-25T18:23:46.215463Z",
     "iopub.status.idle": "2025-04-25T18:23:46.223360Z",
     "shell.execute_reply": "2025-04-25T18:23:46.222684Z"
    },
    "papermill": {
     "duration": 0.011492,
     "end_time": "2025-04-25T18:23:46.224589",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.213097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Data directories\n",
    "    data_root = '/kaggle/input/msasl-process/processdata'\n",
    "    train_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Train')\n",
    "    val_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Val')\n",
    "    test_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Test')\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    num_frames = 16\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomCrop(224, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset = VideoFrameDataset(train_data_path, transform=transform, num_frames=num_frames)\n",
    "    val_dataset = VideoFrameDataset(val_data_path, transform=transform, num_frames=num_frames)\n",
    "    test_dataset = VideoFrameDataset(test_data_path, transform=transform, num_frames=num_frames)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Get classes\n",
    "    classes = train_dataset.classes\n",
    "    num_classes = len(classes)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    print(\"Initializing Early Fusion CNN model...\")\n",
    "    model = EarlyFusionCNN(num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs, scheduler=scheduler, early_stopping_patience=50)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, classes)\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'classes': classes,\n",
    "        'test_acc': test_acc,\n",
    "    }, 'early_fusion_cnn_final_model.pth')\n",
    "    \n",
    "    print(f\"Final model saved with test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4707429a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:23:46.229800Z",
     "iopub.status.busy": "2025-04-25T18:23:46.229606Z",
     "iopub.status.idle": "2025-04-25T22:12:16.626121Z",
     "shell.execute_reply": "2025-04-25T22:12:16.625229Z"
    },
    "papermill": {
     "duration": 13710.408244,
     "end_time": "2025-04-25T22:12:16.634626",
     "exception": false,
     "start_time": "2025-04-25T18:23:46.226382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train samples: 3495\n",
      "Val samples: 850\n",
      "Test samples: 1335\n",
      "Number of classes: 154\n",
      "Initializing Early Fusion CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 171MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 5.1687, Train Accuracy: 1.40%\n",
      "Epoch 1/50, Validation Loss: 4.8800, Validation Accuracy: 4.94%\n",
      "  Saved best model with val accuracy: 4.94%\n",
      "Epoch 2/50, Train Loss: 4.5864, Train Accuracy: 6.15%\n",
      "Epoch 2/50, Validation Loss: 4.6179, Validation Accuracy: 8.47%\n",
      "  Saved best model with val accuracy: 8.47%\n",
      "Epoch 3/50, Train Loss: 4.1599, Train Accuracy: 13.30%\n",
      "Epoch 3/50, Validation Loss: 4.3724, Validation Accuracy: 12.59%\n",
      "  Saved best model with val accuracy: 12.59%\n",
      "Epoch 4/50, Train Loss: 3.7207, Train Accuracy: 21.49%\n",
      "Epoch 4/50, Validation Loss: 4.1523, Validation Accuracy: 15.06%\n",
      "  Saved best model with val accuracy: 15.06%\n",
      "Epoch 5/50, Train Loss: 3.3138, Train Accuracy: 30.76%\n",
      "Epoch 5/50, Validation Loss: 3.9710, Validation Accuracy: 19.53%\n",
      "  Saved best model with val accuracy: 19.53%\n",
      "Epoch 6/50, Train Loss: 2.9708, Train Accuracy: 37.80%\n",
      "Epoch 6/50, Validation Loss: 3.8138, Validation Accuracy: 21.06%\n",
      "  Saved best model with val accuracy: 21.06%\n",
      "Epoch 7/50, Train Loss: 2.6146, Train Accuracy: 47.12%\n",
      "Epoch 7/50, Validation Loss: 3.6945, Validation Accuracy: 23.76%\n",
      "  Saved best model with val accuracy: 23.76%\n",
      "Epoch 8/50, Train Loss: 2.3267, Train Accuracy: 54.31%\n",
      "Epoch 8/50, Validation Loss: 3.6269, Validation Accuracy: 22.82%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 9/50, Train Loss: 2.0777, Train Accuracy: 59.03%\n",
      "Epoch 9/50, Validation Loss: 3.6290, Validation Accuracy: 22.35%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 10/50, Train Loss: 1.8253, Train Accuracy: 65.67%\n",
      "Epoch 10/50, Validation Loss: 3.3908, Validation Accuracy: 25.76%\n",
      "  Saved best model with val accuracy: 25.76%\n",
      "Epoch 11/50, Train Loss: 1.6036, Train Accuracy: 70.82%\n",
      "Epoch 11/50, Validation Loss: 3.2531, Validation Accuracy: 30.24%\n",
      "  Saved best model with val accuracy: 30.24%\n",
      "Epoch 12/50, Train Loss: 1.4186, Train Accuracy: 75.05%\n",
      "Epoch 12/50, Validation Loss: 3.2429, Validation Accuracy: 30.24%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 13/50, Train Loss: 1.2504, Train Accuracy: 78.71%\n",
      "Epoch 13/50, Validation Loss: 3.1908, Validation Accuracy: 31.18%\n",
      "  Saved best model with val accuracy: 31.18%\n",
      "Epoch 14/50, Train Loss: 1.0837, Train Accuracy: 82.15%\n",
      "Epoch 14/50, Validation Loss: 3.1546, Validation Accuracy: 32.00%\n",
      "  Saved best model with val accuracy: 32.00%\n",
      "Epoch 15/50, Train Loss: 0.9663, Train Accuracy: 84.66%\n",
      "Epoch 15/50, Validation Loss: 3.1668, Validation Accuracy: 29.76%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 16/50, Train Loss: 0.8189, Train Accuracy: 87.93%\n",
      "Epoch 16/50, Validation Loss: 3.0174, Validation Accuracy: 34.47%\n",
      "  Saved best model with val accuracy: 34.47%\n",
      "Epoch 17/50, Train Loss: 0.7305, Train Accuracy: 89.41%\n",
      "Epoch 17/50, Validation Loss: 3.0981, Validation Accuracy: 32.47%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 18/50, Train Loss: 0.6319, Train Accuracy: 91.22%\n",
      "Epoch 18/50, Validation Loss: 2.9223, Validation Accuracy: 35.76%\n",
      "  Saved best model with val accuracy: 35.76%\n",
      "Epoch 19/50, Train Loss: 0.5699, Train Accuracy: 92.33%\n",
      "Epoch 19/50, Validation Loss: 3.1148, Validation Accuracy: 33.18%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 20/50, Train Loss: 0.4850, Train Accuracy: 93.19%\n",
      "Epoch 20/50, Validation Loss: 2.9367, Validation Accuracy: 35.29%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 21/50, Train Loss: 0.4209, Train Accuracy: 94.74%\n",
      "Epoch 21/50, Validation Loss: 2.8940, Validation Accuracy: 37.65%\n",
      "  Saved best model with val accuracy: 37.65%\n",
      "Epoch 22/50, Train Loss: 0.3548, Train Accuracy: 96.17%\n",
      "Epoch 22/50, Validation Loss: 3.0248, Validation Accuracy: 38.47%\n",
      "  Saved best model with val accuracy: 38.47%\n",
      "Epoch 23/50, Train Loss: 0.3199, Train Accuracy: 96.19%\n",
      "Epoch 23/50, Validation Loss: 2.9340, Validation Accuracy: 35.18%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 24/50, Train Loss: 0.2870, Train Accuracy: 97.08%\n",
      "Epoch 24/50, Validation Loss: 2.9011, Validation Accuracy: 36.24%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 25/50, Train Loss: 0.2553, Train Accuracy: 97.37%\n",
      "Epoch 25/50, Validation Loss: 2.8552, Validation Accuracy: 38.35%\n",
      "  Early stopping patience: 3/50\n",
      "Epoch 26/50, Train Loss: 0.2247, Train Accuracy: 97.71%\n",
      "Epoch 26/50, Validation Loss: 3.0556, Validation Accuracy: 33.53%\n",
      "  Early stopping patience: 4/50\n",
      "Epoch 27/50, Train Loss: 0.1937, Train Accuracy: 98.05%\n",
      "Epoch 27/50, Validation Loss: 2.9453, Validation Accuracy: 38.59%\n",
      "  Saved best model with val accuracy: 38.59%\n",
      "Epoch 28/50, Train Loss: 0.1966, Train Accuracy: 97.97%\n",
      "Epoch 28/50, Validation Loss: 2.9230, Validation Accuracy: 36.94%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 29/50, Train Loss: 0.1598, Train Accuracy: 98.51%\n",
      "Epoch 29/50, Validation Loss: 2.8732, Validation Accuracy: 37.06%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 30/50, Train Loss: 0.1139, Train Accuracy: 99.17%\n",
      "Epoch 30/50, Validation Loss: 2.7197, Validation Accuracy: 40.71%\n",
      "  Saved best model with val accuracy: 40.71%\n",
      "Epoch 31/50, Train Loss: 0.0968, Train Accuracy: 99.71%\n",
      "Epoch 31/50, Validation Loss: 2.7040, Validation Accuracy: 40.94%\n",
      "  Saved best model with val accuracy: 40.94%\n",
      "Epoch 32/50, Train Loss: 0.0842, Train Accuracy: 99.66%\n",
      "Epoch 32/50, Validation Loss: 2.7005, Validation Accuracy: 41.65%\n",
      "  Saved best model with val accuracy: 41.65%\n",
      "Epoch 33/50, Train Loss: 0.0855, Train Accuracy: 99.54%\n",
      "Epoch 33/50, Validation Loss: 2.7269, Validation Accuracy: 39.88%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 34/50, Train Loss: 0.0827, Train Accuracy: 99.51%\n",
      "Epoch 34/50, Validation Loss: 2.7084, Validation Accuracy: 42.00%\n",
      "  Saved best model with val accuracy: 42.00%\n",
      "Epoch 35/50, Train Loss: 0.0765, Train Accuracy: 99.74%\n",
      "Epoch 35/50, Validation Loss: 2.7217, Validation Accuracy: 40.94%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 36/50, Train Loss: 0.0763, Train Accuracy: 99.80%\n",
      "Epoch 36/50, Validation Loss: 2.7128, Validation Accuracy: 42.24%\n",
      "  Saved best model with val accuracy: 42.24%\n",
      "Epoch 37/50, Train Loss: 0.0746, Train Accuracy: 99.69%\n",
      "Epoch 37/50, Validation Loss: 2.6935, Validation Accuracy: 41.41%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 38/50, Train Loss: 0.0728, Train Accuracy: 99.69%\n",
      "Epoch 38/50, Validation Loss: 2.7068, Validation Accuracy: 41.18%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 39/50, Train Loss: 0.0722, Train Accuracy: 99.80%\n",
      "Epoch 39/50, Validation Loss: 2.7060, Validation Accuracy: 41.65%\n",
      "  Early stopping patience: 3/50\n",
      "Epoch 40/50, Train Loss: 0.0702, Train Accuracy: 99.80%\n",
      "Epoch 40/50, Validation Loss: 2.7264, Validation Accuracy: 40.82%\n",
      "  Early stopping patience: 4/50\n",
      "Epoch 41/50, Train Loss: 0.0692, Train Accuracy: 99.86%\n",
      "Epoch 41/50, Validation Loss: 2.7119, Validation Accuracy: 40.94%\n",
      "  Early stopping patience: 5/50\n",
      "Epoch 42/50, Train Loss: 0.0704, Train Accuracy: 99.71%\n",
      "Epoch 42/50, Validation Loss: 2.7125, Validation Accuracy: 42.24%\n",
      "  Early stopping patience: 6/50\n",
      "Epoch 43/50, Train Loss: 0.0689, Train Accuracy: 99.83%\n",
      "Epoch 43/50, Validation Loss: 2.6880, Validation Accuracy: 41.65%\n",
      "  Early stopping patience: 7/50\n",
      "Epoch 44/50, Train Loss: 0.0693, Train Accuracy: 99.86%\n",
      "Epoch 44/50, Validation Loss: 2.6959, Validation Accuracy: 41.65%\n",
      "  Early stopping patience: 8/50\n",
      "Epoch 45/50, Train Loss: 0.0693, Train Accuracy: 99.80%\n",
      "Epoch 45/50, Validation Loss: 2.6952, Validation Accuracy: 42.47%\n",
      "  Saved best model with val accuracy: 42.47%\n",
      "Epoch 46/50, Train Loss: 0.0702, Train Accuracy: 99.86%\n",
      "Epoch 46/50, Validation Loss: 2.7020, Validation Accuracy: 41.88%\n",
      "  Early stopping patience: 1/50\n",
      "Epoch 47/50, Train Loss: 0.0698, Train Accuracy: 99.80%\n",
      "Epoch 47/50, Validation Loss: 2.6988, Validation Accuracy: 40.47%\n",
      "  Early stopping patience: 2/50\n",
      "Epoch 48/50, Train Loss: 0.0697, Train Accuracy: 99.77%\n",
      "Epoch 48/50, Validation Loss: 2.6946, Validation Accuracy: 41.06%\n",
      "  Early stopping patience: 3/50\n",
      "Epoch 49/50, Train Loss: 0.0698, Train Accuracy: 99.94%\n",
      "Epoch 49/50, Validation Loss: 2.6953, Validation Accuracy: 41.65%\n",
      "  Early stopping patience: 4/50\n",
      "Epoch 50/50, Train Loss: 0.0692, Train Accuracy: 99.83%\n",
      "Epoch 50/50, Validation Loss: 2.7199, Validation Accuracy: 40.71%\n",
      "  Early stopping patience: 5/50\n",
      "Evaluating model...\n",
      "Test Loss: 1.4386, Test Accuracy: 67.87%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       1.00      1.00      1.00         2\n",
      "       again       0.10      0.40      0.16         5\n",
      "         all       0.00      0.00      0.00         4\n",
      "       apple       0.67      0.67      0.67         3\n",
      "        aunt       0.00      0.00      0.00         2\n",
      "         bad       0.25      0.50      0.33         2\n",
      "    bathroom       0.00      0.00      0.00         1\n",
      "   beautiful       0.00      0.00      0.00         6\n",
      "     bicycle       0.43      0.60      0.50         5\n",
      "       black       0.40      0.67      0.50         3\n",
      "        blue       1.00      0.50      0.67         2\n",
      "        book       0.67      0.25      0.36         8\n",
      "         boy       1.00      0.25      0.40         4\n",
      "   boyfriend       1.00      0.33      0.50         3\n",
      "     brother       0.17      0.20      0.18         5\n",
      "       brown       0.50      0.33      0.40         3\n",
      "         bus       0.50      0.50      0.50         2\n",
      "         bye       0.00      0.00      0.00         3\n",
      "       candy       0.20      0.50      0.29         2\n",
      "         cat       0.14      0.50      0.22         2\n",
      "      cheese       0.25      0.50      0.33         4\n",
      "       class       0.57      0.67      0.62         6\n",
      "      coffee       0.00      0.00      0.00         3\n",
      "     college       0.00      0.00      0.00         5\n",
      "       color       0.00      0.00      0.00         3\n",
      "    computer       0.00      0.00      0.00         2\n",
      "      cookie       0.00      0.00      0.00         2\n",
      "      cousin       0.33      0.33      0.33         3\n",
      "         cow       0.14      1.00      0.25         1\n",
      "       dance       0.80      0.80      0.80         5\n",
      "    daughter       0.33      0.33      0.33         3\n",
      "         day       0.00      0.00      0.00         4\n",
      "        deaf       0.60      0.43      0.50         7\n",
      "      doctor       0.18      0.60      0.27         5\n",
      "         dog       0.00      0.00      0.00         4\n",
      "        draw       0.00      0.00      0.00         3\n",
      "       drink       0.50      1.00      0.67         1\n",
      "       early       0.00      0.00      0.00         2\n",
      "         eat       0.23      0.75      0.35         4\n",
      "     english       0.22      0.50      0.31         4\n",
      "     excited       0.67      0.33      0.44         6\n",
      "      family       0.14      0.20      0.17         5\n",
      "      father       0.20      0.25      0.22         4\n",
      "        fine       0.67      0.40      0.50         5\n",
      "      finish       0.38      0.43      0.40         7\n",
      "        fish       0.00      0.00      0.00         3\n",
      "      forget       0.20      0.50      0.29         2\n",
      "      france       0.50      0.20      0.29         5\n",
      "      friend       0.33      1.00      0.50         3\n",
      "        girl       0.00      0.00      0.00         5\n",
      "        good       0.40      0.57      0.47         7\n",
      " grandfather       0.00      0.00      0.00         2\n",
      " grandmother       0.00      0.00      0.00         4\n",
      "       green       0.00      0.00      0.00         2\n",
      "       happy       0.86      0.67      0.75         9\n",
      "        have       0.67      0.33      0.44         6\n",
      "     hearing       0.50      1.00      0.67         2\n",
      "       hello       0.90      0.60      0.72        15\n",
      "        help       0.50      0.33      0.40         3\n",
      "        here       0.22      0.67      0.33         3\n",
      "        home       1.00      0.33      0.50         3\n",
      "       horse       0.14      0.33      0.20         3\n",
      "        hour       0.00      0.00      0.00         3\n",
      "         how       0.75      0.60      0.67         5\n",
      "    how_many       0.60      1.00      0.75         6\n",
      "      hungry       1.00      0.50      0.67         2\n",
      "        hurt       0.60      0.75      0.67         4\n",
      "     husband       0.33      1.00      0.50         1\n",
      "      jacket       0.00      0.00      0.00         2\n",
      "        know       0.67      1.00      0.80         4\n",
      "       learn       0.40      0.33      0.36         6\n",
      "       light       0.20      0.14      0.17         7\n",
      "        like       0.00      0.00      0.00         5\n",
      "        live       0.33      0.50      0.40         4\n",
      "        lost       0.00      0.00      0.00         7\n",
      "         man       0.00      0.00      0.00         3\n",
      "       marry       0.00      0.00      0.00         3\n",
      "          me       0.00      0.00      0.00         3\n",
      "        meet       1.00      1.00      1.00         2\n",
      "        milk       0.00      0.00      0.00         2\n",
      "      monday       0.00      0.00      0.00         1\n",
      "      mother       0.00      0.00      0.00         2\n",
      "          my       0.25      0.50      0.33         4\n",
      "        name       0.67      0.67      0.67         3\n",
      "        nice       0.50      0.25      0.33         4\n",
      "       night       0.00      0.00      0.00         3\n",
      "          no       0.71      0.62      0.67         8\n",
      "    not know       0.00      0.00      0.00         2\n",
      "     nothing       0.00      0.00      0.00         4\n",
      "       nurse       1.00      0.20      0.33         5\n",
      "         old       0.00      0.00      0.00         1\n",
      "      orange       0.22      0.40      0.29         5\n",
      "       paper       0.33      0.25      0.29         8\n",
      "      pencil       0.00      0.00      0.00         3\n",
      "        pink       0.00      0.00      0.00         2\n",
      "        play       0.67      0.50      0.57         4\n",
      "      please       0.60      0.60      0.60         5\n",
      "   principal       0.00      0.00      0.00         2\n",
      "      purple       0.09      0.50      0.15         2\n",
      "       quiet       0.20      0.17      0.18         6\n",
      "        read       0.75      0.50      0.60         6\n",
      "         red       0.00      0.00      0.00         3\n",
      "       right       0.50      0.14      0.22         7\n",
      "      russia       0.00      0.00      0.00         4\n",
      "         sad       0.40      0.80      0.53         5\n",
      "        same       0.00      0.00      0.00         2\n",
      "    sandwich       0.00      0.00      0.00         2\n",
      "    saturday       0.00      0.00      0.00         3\n",
      "      school       0.25      0.25      0.25         8\n",
      "       shirt       0.00      0.00      0.00         2\n",
      "       shoes       1.00      0.50      0.67         2\n",
      "        sick       0.29      0.67      0.40         3\n",
      "        sign       0.29      0.25      0.27         8\n",
      "      sister       0.40      0.40      0.40         5\n",
      "         sit       0.50      0.83      0.62         6\n",
      "        slow       0.33      0.17      0.22         6\n",
      "      soccer       0.00      0.00      0.00         3\n",
      "        soda       0.33      1.00      0.50         1\n",
      "       sorry       0.33      0.25      0.29         4\n",
      "      spring       0.42      0.71      0.53         7\n",
      "     student       0.13      0.50      0.21         4\n",
      "      sunday       1.00      0.33      0.50         3\n",
      "       table       0.78      0.95      0.86        19\n",
      "         tea       0.90      0.90      0.90        20\n",
      "     teacher       0.97      0.92      0.95        39\n",
      "    thursday       1.00      0.76      0.86        21\n",
      "        time       0.79      0.93      0.85        28\n",
      "       tired       1.00      0.83      0.91        36\n",
      "       today       0.89      0.89      0.89        18\n",
      "    tomorrow       0.79      0.88      0.83        25\n",
      "      turkey       1.00      0.81      0.90        27\n",
      "       uncle       1.00      0.92      0.96        26\n",
      "  understand       0.93      0.90      0.92        30\n",
      "        walk       0.89      0.83      0.86        30\n",
      "        want       0.90      0.90      0.90        39\n",
      "       water       0.96      0.90      0.93        30\n",
      "   wednesday       0.86      0.82      0.84        22\n",
      "        what       0.71      0.91      0.80        35\n",
      "        when       0.83      0.89      0.86        28\n",
      "       where       0.97      0.93      0.95        30\n",
      "       white       0.93      0.85      0.89        33\n",
      "         who       0.89      0.81      0.85        21\n",
      "         why       1.00      0.72      0.84        18\n",
      "        wife       1.00      0.90      0.95        21\n",
      "       woman       0.95      0.81      0.88        26\n",
      "        wood       1.00      0.82      0.90        17\n",
      "        work       0.79      0.65      0.71        17\n",
      "       write       0.89      0.77      0.83        31\n",
      "       wrong       1.00      0.87      0.93        23\n",
      "        year       0.92      0.88      0.90        26\n",
      "      yellow       0.93      0.78      0.85        32\n",
      "         yes       0.94      0.92      0.93        37\n",
      "         you       1.00      0.89      0.94        27\n",
      "        your       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.68      1335\n",
      "   macro avg       0.44      0.44      0.41      1335\n",
      "weighted avg       0.72      0.68      0.68      1335\n",
      "\n",
      "Final model saved with test accuracy: 67.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7073108,
     "sourceId": 11325443,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13738.414717,
   "end_time": "2025-04-25T22:12:20.334427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T18:23:21.919710",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
