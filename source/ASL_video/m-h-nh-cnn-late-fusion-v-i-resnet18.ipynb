{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8261771a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:31.029438Z",
     "iopub.status.busy": "2025-04-25T18:28:31.029232Z",
     "iopub.status.idle": "2025-04-25T18:28:42.709071Z",
     "shell.execute_reply": "2025-04-25T18:28:42.708225Z"
    },
    "papermill": {
     "duration": 11.684474,
     "end_time": "2025-04-25T18:28:42.710547",
     "exception": false,
     "start_time": "2025-04-25T18:28:31.026073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c200170b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.715896Z",
     "iopub.status.busy": "2025-04-25T18:28:42.715332Z",
     "iopub.status.idle": "2025-04-25T18:28:42.766364Z",
     "shell.execute_reply": "2025-04-25T18:28:42.765619Z"
    },
    "papermill": {
     "duration": 0.054597,
     "end_time": "2025-04-25T18:28:42.767527",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.712930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d01ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.772191Z",
     "iopub.status.busy": "2025-04-25T18:28:42.771961Z",
     "iopub.status.idle": "2025-04-25T18:28:42.780524Z",
     "shell.execute_reply": "2025-04-25T18:28:42.779819Z"
    },
    "papermill": {
     "duration": 0.012072,
     "end_time": "2025-04-25T18:28:42.781577",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.769505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset  # Import Dataset\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, num_frames=16):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.classes = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        \n",
    "        # Lấy video và nhãn từ thư mục\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_path, class_name)\n",
    "            for video_folder in os.listdir(class_dir):\n",
    "                video_path = os.path.join(class_dir, video_folder)\n",
    "                if os.path.isdir(video_path):\n",
    "                    self.samples.append((video_path, self.class_to_idx[class_name]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.samples[idx]\n",
    "        frame_files = sorted([f for f in os.listdir(video_path) if f.endswith('.jpg')])\n",
    "        frames = []\n",
    "        \n",
    "        # Chọn num_frames frame, hoặc tất cả frame nếu ít hơn\n",
    "        actual_num_frames = min(self.num_frames, len(frame_files))\n",
    "        selected_indices = np.linspace(0, len(frame_files) - 1, num=actual_num_frames, dtype=int)\n",
    "        \n",
    "        for i in selected_indices:\n",
    "            if i < len(frame_files):\n",
    "                frame_path = os.path.join(video_path, frame_files[i])\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is None:\n",
    "                    frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                frames.append(frame)\n",
    "        \n",
    "        while len(frames) < self.num_frames:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "        \n",
    "        frames = torch.stack(frames)\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14585cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.785875Z",
     "iopub.status.busy": "2025-04-25T18:28:42.785667Z",
     "iopub.status.idle": "2025-04-25T18:28:42.790793Z",
     "shell.execute_reply": "2025-04-25T18:28:42.790141Z"
    },
    "papermill": {
     "duration": 0.008547,
     "end_time": "2025-04-25T18:28:42.791966",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.783419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mô hình CNN (Single-Frame CNN) với ResNet + MLP\n",
    "class SingleFrameCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5):\n",
    "        super(SingleFrameCNN, self).__init__()\n",
    "        \n",
    "        # Sử dụng ResNet18 đã được pre-trained\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # Bỏ fully connected layer cuối\n",
    "        \n",
    "        # MLP để phân loại\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)  # 512 là kích thước đầu ra của ResNet\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, c, h, w = x.shape\n",
    "        # Reshape để xử lý từng frame một\n",
    "        x = x.view(batch_size * num_frames, c, h, w)\n",
    "        # Trích xuất đặc trưng từ ResNet\n",
    "        x = self.resnet(x)\n",
    "        # Reshape lại để MLP xử lý\n",
    "        x = x.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Tính trung bình các logits\n",
    "        x = x.mean(dim=1)  # Trung bình trên các frame\n",
    "        \n",
    "        # Đưa qua MLP để phân loại\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022a082a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.796479Z",
     "iopub.status.busy": "2025-04-25T18:28:42.796278Z",
     "iopub.status.idle": "2025-04-25T18:28:42.802647Z",
     "shell.execute_reply": "2025-04-25T18:28:42.801989Z"
    },
    "papermill": {
     "duration": 0.00982,
     "end_time": "2025-04-25T18:28:42.803632",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.793812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, classes):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(min(20, len(classes)), min(18, len(classes))))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f96cd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.807911Z",
     "iopub.status.busy": "2025-04-25T18:28:42.807671Z",
     "iopub.status.idle": "2025-04-25T18:28:42.811089Z",
     "shell.execute_reply": "2025-04-25T18:28:42.810358Z"
    },
    "papermill": {
     "duration": 0.006718,
     "end_time": "2025-04-25T18:28:42.812145",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.805427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac42ee68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.816675Z",
     "iopub.status.busy": "2025-04-25T18:28:42.816471Z",
     "iopub.status.idle": "2025-04-25T18:28:42.827165Z",
     "shell.execute_reply": "2025-04-25T18:28:42.826656Z"
    },
    "papermill": {
     "duration": 0.014113,
     "end_time": "2025-04-25T18:28:42.828138",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.814025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25, scheduler=None, early_stopping_patience=50):\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Lists to store training history\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Track the actual number of epochs completed due to early stopping\n",
    "    actual_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {epoch_train_acc:.2f}%\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * correct / total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Step the scheduler if applicable\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_single_frame_cnn_model.pth')\n",
    "            print(f\"  Saved best model with val accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  Early stopping patience: {patience_counter}/{early_stopping_patience}\")\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Count the actual number of epochs run\n",
    "        actual_epochs = epoch + 1\n",
    "\n",
    "    # Plot training and validation loss/accuracy with dynamic epoch count\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_losses[:actual_epochs], label='Train Loss')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_losses[:actual_epochs], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, actual_epochs + 1), train_accuracies[:actual_epochs], label='Train Accuracy')\n",
    "    plt.plot(range(1, actual_epochs + 1), val_accuracies[:actual_epochs], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33eda8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.832813Z",
     "iopub.status.busy": "2025-04-25T18:28:42.832607Z",
     "iopub.status.idle": "2025-04-25T18:28:42.841053Z",
     "shell.execute_reply": "2025-04-25T18:28:42.840570Z"
    },
    "papermill": {
     "duration": 0.012011,
     "end_time": "2025-04-25T18:28:42.842065",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.830054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Cấu hình dữ liệu\n",
    "    data_root = '/kaggle/input/msasl-process/processdata'\n",
    "    train_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Train')\n",
    "    val_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Val')\n",
    "    test_data_path = os.path.join(data_root, 'processed_data_MS_ASL100_Test')\n",
    "    \n",
    "    # Các tham số huấn luyện\n",
    "    batch_size = 32\n",
    "    num_frames = 16\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Định nghĩa các phép biến đổi \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomCrop(224, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Tạo datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset = VideoFrameDataset(train_data_path, transform=transform, num_frames=num_frames)\n",
    "    val_dataset = VideoFrameDataset(val_data_path, transform=transform, num_frames=num_frames)\n",
    "    test_dataset = VideoFrameDataset(test_data_path, transform=transform, num_frames=num_frames)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Tạo dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Lấy danh sách các lớp\n",
    "    classes = train_dataset.classes\n",
    "    num_classes = len(classes)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    print(\"Initializing Single-Frame CNN model...\")\n",
    "    model = SingleFrameCNN(num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Định nghĩa loss function và optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=num_epochs, scheduler=scheduler, early_stopping_patience=10\n",
    "    )\n",
    "    \n",
    "    # Kiểm tra và tải mô hình tốt nhất\n",
    "    model_path = 'best_single_frame_cnn_model.pth'\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading best model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(f\"Model not found at {model_path}, skipping model loading.\")\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, classes)\n",
    "    \n",
    "    # Lưu mô hình cuối cùng\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'classes': classes,\n",
    "        'test_acc': test_acc,\n",
    "    }, 'single_frame_cnn_final_model.pth')\n",
    "    \n",
    "    print(f\"Final model saved with test accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4871b46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T18:28:42.847640Z",
     "iopub.status.busy": "2025-04-25T18:28:42.847400Z",
     "iopub.status.idle": "2025-04-25T21:20:09.582553Z",
     "shell.execute_reply": "2025-04-25T21:20:09.580991Z"
    },
    "papermill": {
     "duration": 10286.739269,
     "end_time": "2025-04-25T21:20:09.584363",
     "exception": false,
     "start_time": "2025-04-25T18:28:42.845094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train samples: 3495\n",
      "Val samples: 850\n",
      "Test samples: 1335\n",
      "Number of classes: 154\n",
      "Initializing Single-Frame CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 208MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 5.1461, Train Accuracy: 1.29%\n",
      "Epoch 1/50, Validation Loss: 4.8401, Validation Accuracy: 3.53%\n",
      "  Saved best model with val accuracy: 3.53%\n",
      "Epoch 2/50, Train Loss: 4.5500, Train Accuracy: 7.10%\n",
      "Epoch 2/50, Validation Loss: 4.5171, Validation Accuracy: 9.41%\n",
      "  Saved best model with val accuracy: 9.41%\n",
      "Epoch 3/50, Train Loss: 4.0685, Train Accuracy: 15.57%\n",
      "Epoch 3/50, Validation Loss: 4.3517, Validation Accuracy: 12.00%\n",
      "  Saved best model with val accuracy: 12.00%\n",
      "Epoch 4/50, Train Loss: 3.6655, Train Accuracy: 23.58%\n",
      "Epoch 4/50, Validation Loss: 4.0719, Validation Accuracy: 16.24%\n",
      "  Saved best model with val accuracy: 16.24%\n",
      "Epoch 5/50, Train Loss: 3.2732, Train Accuracy: 32.19%\n",
      "Epoch 5/50, Validation Loss: 3.8512, Validation Accuracy: 20.59%\n",
      "  Saved best model with val accuracy: 20.59%\n",
      "Epoch 6/50, Train Loss: 2.9172, Train Accuracy: 39.77%\n",
      "Epoch 6/50, Validation Loss: 3.8239, Validation Accuracy: 19.18%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 7/50, Train Loss: 2.5673, Train Accuracy: 47.84%\n",
      "Epoch 7/50, Validation Loss: 3.6733, Validation Accuracy: 26.00%\n",
      "  Saved best model with val accuracy: 26.00%\n",
      "Epoch 8/50, Train Loss: 2.2905, Train Accuracy: 54.56%\n",
      "Epoch 8/50, Validation Loss: 3.4586, Validation Accuracy: 25.41%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 9/50, Train Loss: 2.0217, Train Accuracy: 61.03%\n",
      "Epoch 9/50, Validation Loss: 3.4144, Validation Accuracy: 28.12%\n",
      "  Saved best model with val accuracy: 28.12%\n",
      "Epoch 10/50, Train Loss: 1.7806, Train Accuracy: 67.64%\n",
      "Epoch 10/50, Validation Loss: 3.3612, Validation Accuracy: 27.06%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 11/50, Train Loss: 1.5750, Train Accuracy: 70.70%\n",
      "Epoch 11/50, Validation Loss: 3.1807, Validation Accuracy: 29.88%\n",
      "  Saved best model with val accuracy: 29.88%\n",
      "Epoch 12/50, Train Loss: 1.3837, Train Accuracy: 75.25%\n",
      "Epoch 12/50, Validation Loss: 3.0623, Validation Accuracy: 34.24%\n",
      "  Saved best model with val accuracy: 34.24%\n",
      "Epoch 13/50, Train Loss: 1.1889, Train Accuracy: 80.49%\n",
      "Epoch 13/50, Validation Loss: 3.1429, Validation Accuracy: 31.53%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 14/50, Train Loss: 1.0729, Train Accuracy: 82.29%\n",
      "Epoch 14/50, Validation Loss: 3.0831, Validation Accuracy: 31.88%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 15/50, Train Loss: 0.9387, Train Accuracy: 84.18%\n",
      "Epoch 15/50, Validation Loss: 2.9958, Validation Accuracy: 35.53%\n",
      "  Saved best model with val accuracy: 35.53%\n",
      "Epoch 16/50, Train Loss: 0.7914, Train Accuracy: 88.53%\n",
      "Epoch 16/50, Validation Loss: 2.9390, Validation Accuracy: 34.59%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 17/50, Train Loss: 0.6889, Train Accuracy: 89.99%\n",
      "Epoch 17/50, Validation Loss: 2.8981, Validation Accuracy: 36.82%\n",
      "  Saved best model with val accuracy: 36.82%\n",
      "Epoch 18/50, Train Loss: 0.6067, Train Accuracy: 92.22%\n",
      "Epoch 18/50, Validation Loss: 2.8329, Validation Accuracy: 37.41%\n",
      "  Saved best model with val accuracy: 37.41%\n",
      "Epoch 19/50, Train Loss: 0.5407, Train Accuracy: 92.73%\n",
      "Epoch 19/50, Validation Loss: 2.9735, Validation Accuracy: 36.59%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 20/50, Train Loss: 0.4801, Train Accuracy: 94.11%\n",
      "Epoch 20/50, Validation Loss: 2.9169, Validation Accuracy: 35.88%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 21/50, Train Loss: 0.4168, Train Accuracy: 95.11%\n",
      "Epoch 21/50, Validation Loss: 2.8776, Validation Accuracy: 40.12%\n",
      "  Saved best model with val accuracy: 40.12%\n",
      "Epoch 22/50, Train Loss: 0.3586, Train Accuracy: 96.14%\n",
      "Epoch 22/50, Validation Loss: 2.8214, Validation Accuracy: 39.18%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 23/50, Train Loss: 0.3071, Train Accuracy: 96.71%\n",
      "Epoch 23/50, Validation Loss: 2.8082, Validation Accuracy: 36.71%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 24/50, Train Loss: 0.2707, Train Accuracy: 97.40%\n",
      "Epoch 24/50, Validation Loss: 2.7926, Validation Accuracy: 40.00%\n",
      "  Early stopping patience: 3/10\n",
      "Epoch 25/50, Train Loss: 0.2528, Train Accuracy: 97.37%\n",
      "Epoch 25/50, Validation Loss: 2.7454, Validation Accuracy: 38.71%\n",
      "  Early stopping patience: 4/10\n",
      "Epoch 26/50, Train Loss: 0.2159, Train Accuracy: 98.00%\n",
      "Epoch 26/50, Validation Loss: 2.8194, Validation Accuracy: 39.53%\n",
      "  Early stopping patience: 5/10\n",
      "Epoch 27/50, Train Loss: 0.1960, Train Accuracy: 98.23%\n",
      "Epoch 27/50, Validation Loss: 2.7487, Validation Accuracy: 40.59%\n",
      "  Saved best model with val accuracy: 40.59%\n",
      "Epoch 28/50, Train Loss: 0.1680, Train Accuracy: 98.66%\n",
      "Epoch 28/50, Validation Loss: 2.7773, Validation Accuracy: 41.65%\n",
      "  Saved best model with val accuracy: 41.65%\n",
      "Epoch 29/50, Train Loss: 0.1707, Train Accuracy: 98.14%\n",
      "Epoch 29/50, Validation Loss: 2.7878, Validation Accuracy: 40.35%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 30/50, Train Loss: 0.1196, Train Accuracy: 99.34%\n",
      "Epoch 30/50, Validation Loss: 2.6239, Validation Accuracy: 42.24%\n",
      "  Saved best model with val accuracy: 42.24%\n",
      "Epoch 31/50, Train Loss: 0.0979, Train Accuracy: 99.48%\n",
      "Epoch 31/50, Validation Loss: 2.6519, Validation Accuracy: 42.47%\n",
      "  Saved best model with val accuracy: 42.47%\n",
      "Epoch 32/50, Train Loss: 0.0896, Train Accuracy: 99.51%\n",
      "Epoch 32/50, Validation Loss: 2.6407, Validation Accuracy: 42.35%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 33/50, Train Loss: 0.0825, Train Accuracy: 99.80%\n",
      "Epoch 33/50, Validation Loss: 2.6267, Validation Accuracy: 42.94%\n",
      "  Saved best model with val accuracy: 42.94%\n",
      "Epoch 34/50, Train Loss: 0.0789, Train Accuracy: 99.69%\n",
      "Epoch 34/50, Validation Loss: 2.6696, Validation Accuracy: 42.24%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 35/50, Train Loss: 0.0735, Train Accuracy: 99.77%\n",
      "Epoch 35/50, Validation Loss: 2.6274, Validation Accuracy: 42.35%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 36/50, Train Loss: 0.0754, Train Accuracy: 99.77%\n",
      "Epoch 36/50, Validation Loss: 2.6422, Validation Accuracy: 42.94%\n",
      "  Early stopping patience: 3/10\n",
      "Epoch 37/50, Train Loss: 0.0735, Train Accuracy: 99.94%\n",
      "Epoch 37/50, Validation Loss: 2.6383, Validation Accuracy: 43.29%\n",
      "  Saved best model with val accuracy: 43.29%\n",
      "Epoch 38/50, Train Loss: 0.0748, Train Accuracy: 99.74%\n",
      "Epoch 38/50, Validation Loss: 2.6546, Validation Accuracy: 42.71%\n",
      "  Early stopping patience: 1/10\n",
      "Epoch 39/50, Train Loss: 0.0760, Train Accuracy: 99.71%\n",
      "Epoch 39/50, Validation Loss: 2.6461, Validation Accuracy: 43.29%\n",
      "  Early stopping patience: 2/10\n",
      "Epoch 40/50, Train Loss: 0.0753, Train Accuracy: 99.74%\n",
      "Epoch 40/50, Validation Loss: 2.6365, Validation Accuracy: 42.24%\n",
      "  Early stopping patience: 3/10\n",
      "Epoch 41/50, Train Loss: 0.0724, Train Accuracy: 99.86%\n",
      "Epoch 41/50, Validation Loss: 2.6611, Validation Accuracy: 42.24%\n",
      "  Early stopping patience: 4/10\n",
      "Epoch 42/50, Train Loss: 0.0710, Train Accuracy: 99.83%\n",
      "Epoch 42/50, Validation Loss: 2.6395, Validation Accuracy: 42.82%\n",
      "  Early stopping patience: 5/10\n",
      "Epoch 43/50, Train Loss: 0.0723, Train Accuracy: 99.69%\n",
      "Epoch 43/50, Validation Loss: 2.6497, Validation Accuracy: 42.24%\n",
      "  Early stopping patience: 6/10\n",
      "Epoch 44/50, Train Loss: 0.0728, Train Accuracy: 99.80%\n",
      "Epoch 44/50, Validation Loss: 2.6474, Validation Accuracy: 41.29%\n",
      "  Early stopping patience: 7/10\n",
      "Epoch 45/50, Train Loss: 0.0733, Train Accuracy: 99.71%\n",
      "Epoch 45/50, Validation Loss: 2.6412, Validation Accuracy: 42.12%\n",
      "  Early stopping patience: 8/10\n",
      "Epoch 46/50, Train Loss: 0.0743, Train Accuracy: 99.83%\n",
      "Epoch 46/50, Validation Loss: 2.6278, Validation Accuracy: 42.59%\n",
      "  Early stopping patience: 9/10\n",
      "Epoch 47/50, Train Loss: 0.0690, Train Accuracy: 99.89%\n",
      "Epoch 47/50, Validation Loss: 2.6571, Validation Accuracy: 41.88%\n",
      "  Early stopping patience: 10/10\n",
      "Early stopping triggered at epoch 47\n",
      "Loading best model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2791998620.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4337, Test Accuracy: 67.72%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      afraid       1.00      1.00      1.00         2\n",
      "       again       0.09      0.40      0.15         5\n",
      "         all       0.00      0.00      0.00         4\n",
      "       apple       1.00      0.67      0.80         3\n",
      "        aunt       0.00      0.00      0.00         2\n",
      "         bad       0.00      0.00      0.00         2\n",
      "    bathroom       0.00      0.00      0.00         1\n",
      "   beautiful       0.00      0.00      0.00         6\n",
      "     bicycle       0.60      0.60      0.60         5\n",
      "       black       0.50      0.67      0.57         3\n",
      "        blue       0.00      0.00      0.00         2\n",
      "        book       1.00      0.25      0.40         8\n",
      "         boy       0.00      0.00      0.00         4\n",
      "   boyfriend       1.00      0.33      0.50         3\n",
      "     brother       0.25      0.20      0.22         5\n",
      "       brown       1.00      0.33      0.50         3\n",
      "         bus       0.00      0.00      0.00         2\n",
      "         bye       0.00      0.00      0.00         3\n",
      "       candy       1.00      1.00      1.00         2\n",
      "         cat       0.29      1.00      0.44         2\n",
      "      cheese       0.25      0.25      0.25         4\n",
      "       class       0.67      0.67      0.67         6\n",
      "      coffee       0.00      0.00      0.00         3\n",
      "     college       0.10      0.20      0.13         5\n",
      "       color       0.00      0.00      0.00         3\n",
      "    computer       0.00      0.00      0.00         2\n",
      "      cookie       0.00      0.00      0.00         2\n",
      "      cousin       0.50      0.67      0.57         3\n",
      "         cow       0.00      0.00      0.00         1\n",
      "       dance       0.67      0.80      0.73         5\n",
      "    daughter       0.33      0.33      0.33         3\n",
      "         day       0.00      0.00      0.00         4\n",
      "        deaf       0.50      0.29      0.36         7\n",
      "      doctor       0.17      0.20      0.18         5\n",
      "         dog       0.00      0.00      0.00         4\n",
      "        draw       0.00      0.00      0.00         3\n",
      "       drink       0.20      1.00      0.33         1\n",
      "       early       0.00      0.00      0.00         2\n",
      "         eat       0.30      0.75      0.43         4\n",
      "     english       0.33      0.25      0.29         4\n",
      "     excited       0.60      0.50      0.55         6\n",
      "      family       0.38      0.60      0.46         5\n",
      "      father       0.50      0.50      0.50         4\n",
      "        fine       1.00      0.20      0.33         5\n",
      "      finish       0.50      0.43      0.46         7\n",
      "        fish       0.00      0.00      0.00         3\n",
      "      forget       0.20      0.50      0.29         2\n",
      "      france       0.00      0.00      0.00         5\n",
      "      friend       0.38      1.00      0.55         3\n",
      "        girl       0.17      0.20      0.18         5\n",
      "        good       0.22      0.57      0.32         7\n",
      " grandfather       0.00      0.00      0.00         2\n",
      " grandmother       0.00      0.00      0.00         4\n",
      "       green       0.00      0.00      0.00         2\n",
      "       happy       0.58      0.78      0.67         9\n",
      "        have       1.00      0.17      0.29         6\n",
      "     hearing       0.50      0.50      0.50         2\n",
      "       hello       0.60      0.40      0.48        15\n",
      "        help       0.00      0.00      0.00         3\n",
      "        here       0.17      0.33      0.22         3\n",
      "        home       0.50      0.67      0.57         3\n",
      "       horse       0.22      0.67      0.33         3\n",
      "        hour       0.33      0.33      0.33         3\n",
      "         how       1.00      0.80      0.89         5\n",
      "    how_many       0.60      1.00      0.75         6\n",
      "      hungry       1.00      0.50      0.67         2\n",
      "        hurt       0.75      0.75      0.75         4\n",
      "     husband       0.00      0.00      0.00         1\n",
      "      jacket       0.00      0.00      0.00         2\n",
      "        know       1.00      1.00      1.00         4\n",
      "       learn       0.29      0.33      0.31         6\n",
      "       light       0.00      0.00      0.00         7\n",
      "        like       0.00      0.00      0.00         5\n",
      "        live       0.44      1.00      0.62         4\n",
      "        lost       0.00      0.00      0.00         7\n",
      "         man       0.00      0.00      0.00         3\n",
      "       marry       0.00      0.00      0.00         3\n",
      "          me       0.00      0.00      0.00         3\n",
      "        meet       0.00      0.00      0.00         2\n",
      "        milk       0.00      0.00      0.00         2\n",
      "      monday       0.00      0.00      0.00         1\n",
      "      mother       0.40      1.00      0.57         2\n",
      "          my       0.00      0.00      0.00         4\n",
      "        name       0.67      0.67      0.67         3\n",
      "        nice       0.12      0.25      0.17         4\n",
      "       night       0.00      0.00      0.00         3\n",
      "          no       0.75      0.38      0.50         8\n",
      "    not know       0.00      0.00      0.00         2\n",
      "     nothing       0.00      0.00      0.00         4\n",
      "       nurse       1.00      0.20      0.33         5\n",
      "         old       0.00      0.00      0.00         1\n",
      "      orange       0.33      0.20      0.25         5\n",
      "       paper       0.29      0.25      0.27         8\n",
      "      pencil       0.00      0.00      0.00         3\n",
      "        pink       0.00      0.00      0.00         2\n",
      "        play       1.00      0.25      0.40         4\n",
      "      please       0.40      0.80      0.53         5\n",
      "   principal       0.00      0.00      0.00         2\n",
      "      purple       0.20      0.50      0.29         2\n",
      "       quiet       0.00      0.00      0.00         6\n",
      "        read       0.60      0.50      0.55         6\n",
      "         red       0.00      0.00      0.00         3\n",
      "       right       0.50      0.14      0.22         7\n",
      "      russia       0.00      0.00      0.00         4\n",
      "         sad       1.00      0.60      0.75         5\n",
      "        same       0.00      0.00      0.00         2\n",
      "    sandwich       0.00      0.00      0.00         2\n",
      "    saturday       0.00      0.00      0.00         3\n",
      "      school       0.20      0.25      0.22         8\n",
      "       shirt       0.33      0.50      0.40         2\n",
      "       shoes       0.50      0.50      0.50         2\n",
      "        sick       0.21      1.00      0.35         3\n",
      "        sign       0.33      0.25      0.29         8\n",
      "      sister       0.50      0.80      0.62         5\n",
      "         sit       0.33      0.17      0.22         6\n",
      "        slow       0.50      0.67      0.57         6\n",
      "      soccer       0.20      0.33      0.25         3\n",
      "        soda       0.20      1.00      0.33         1\n",
      "       sorry       1.00      0.50      0.67         4\n",
      "      spring       0.23      0.43      0.30         7\n",
      "     student       0.12      0.50      0.19         4\n",
      "      sunday       1.00      0.33      0.50         3\n",
      "       table       0.90      1.00      0.95        19\n",
      "         tea       0.95      0.90      0.92        20\n",
      "     teacher       0.95      0.92      0.94        39\n",
      "    thursday       1.00      0.76      0.86        21\n",
      "        time       0.89      0.89      0.89        28\n",
      "       tired       1.00      0.86      0.93        36\n",
      "       today       0.88      0.83      0.86        18\n",
      "    tomorrow       1.00      0.92      0.96        25\n",
      "      turkey       1.00      0.85      0.92        27\n",
      "       uncle       1.00      0.96      0.98        26\n",
      "  understand       0.87      0.87      0.87        30\n",
      "        walk       0.89      0.83      0.86        30\n",
      "        want       1.00      0.90      0.95        39\n",
      "       water       0.93      0.90      0.92        30\n",
      "   wednesday       0.89      0.77      0.83        22\n",
      "        what       0.69      0.94      0.80        35\n",
      "        when       0.78      1.00      0.88        28\n",
      "       where       0.88      0.97      0.92        30\n",
      "       white       0.94      0.88      0.91        33\n",
      "         who       0.86      0.90      0.88        21\n",
      "         why       0.76      0.72      0.74        18\n",
      "        wife       1.00      0.90      0.95        21\n",
      "       woman       0.96      0.85      0.90        26\n",
      "        wood       0.88      0.82      0.85        17\n",
      "        work       1.00      0.71      0.83        17\n",
      "       write       0.91      0.68      0.78        31\n",
      "       wrong       1.00      0.87      0.93        23\n",
      "        year       0.96      0.85      0.90        26\n",
      "      yellow       0.77      0.84      0.81        32\n",
      "         yes       1.00      0.92      0.96        37\n",
      "         you       0.88      0.85      0.87        27\n",
      "        your       0.86      0.75      0.80        24\n",
      "\n",
      "    accuracy                           0.68      1335\n",
      "   macro avg       0.43      0.43      0.40      1335\n",
      "weighted avg       0.72      0.68      0.68      1335\n",
      "\n",
      "Final model saved with test accuracy: 67.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7073108,
     "sourceId": 11325443,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10305.300751,
   "end_time": "2025-04-25T21:20:12.317251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-25T18:28:27.016500",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
